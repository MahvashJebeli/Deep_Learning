{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de016f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning, Convolutional Neural Networks\n",
    "# This code is my practice from the online course on https://www.youtube.com/playlist?list=PLQVvvaa0QuDfhTox0AjmQ6tvTgMBZBEXN\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os # to iterate through directories and join paths\n",
    "import cv2 # to perform image operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a9418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the images\n",
    "DATADIR = r\"C:\\Users\\mahva\\Jupyter\\Deep Learning\\PetImages\"\n",
    "CATEGORIES = [\"Dog\", \"Cat\"]\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DATADIR, category) # Path\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE) # turning to grayscale to remove unnecessary info\n",
    "        plt.imshow(img_array, cmap = \"gray\")\n",
    "        plt.show()\n",
    "        break\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c969447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making al the images same size and shape\n",
    "IMG_SIZE = 120\n",
    "new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "plt.imshow(new_array, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354fa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training data\n",
    "training_data = []\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category) # Path\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                training_data.append([new_array, class_num])\n",
    "#                 print(\"1\")\n",
    "            except Exception as e:\n",
    "                pass # passing through the broken images!\n",
    "\n",
    "create_training_data()\n",
    "print(len(training_data))\n",
    "\n",
    "# shuffling the data\n",
    "import random\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd29207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation to feed into the NN\n",
    "X = []\n",
    "y = []\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1) # -1 catches how many features we do have, \n",
    "                                                   # 1 because it is grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdafebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just saving the data to later tweak easier!!\n",
    "pickle_out = open(\"X.pickle\", \"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\", \"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bab37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening saved data\n",
    "X = pickle.load(open(\"X.pickle\", \"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142dd2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "X = X/255.0 # Scaling (normalizing) the imagery data\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3,3), input_shape = X.shape[1:])) # first layer\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3))) # second layer\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten()) # convolutional data is 2D, we need to flatten it.\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(1)) # output \n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480b5941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=['accuracy']) # binary because it is dog vs cat, we can go categorical as well.\n",
    "\n",
    "# Fitting the model\n",
    "model.fit(X, y, batch_size=50, epochs=10, validation_split=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
